{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRwjeuBeVraeS78MTKQby9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CYaiche/Machine_Learning/blob/master/projet5/embedding_topic_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Supervised topic modeling : NN approach\n",
        "\n"
      ],
      "metadata": {
        "id": "Exy2TPsxHFl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gensim.corpora as corpora\n",
        "from  gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.metrics import jaccard_score, average_precision_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Embedding, Dense, Input, Embedding\n"
      ],
      "metadata": {
        "id": "Nebb9sgrHSLV"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdU9k2KRHFV2",
        "outputId": "4fb108d5-78e3-480a-be6a-3e2d41a3e207"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "vawUwgJuG6E0"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_title_train = np.load(\"/content/drive/MyDrive/OpenClassroom/X_title_train.npy\"     , allow_pickle=True)\n",
        "X_corpus_train = np.load(\"/content/drive/MyDrive/OpenClassroom/X_corpus_train.npy\",   allow_pickle=True)\n",
        "X_title_test = np.load(\"/content/drive/MyDrive/OpenClassroom/X_title_test.npy\"     , allow_pickle=True)\n",
        "X_corpus_test = np.load(\"/content/drive/MyDrive/OpenClassroom/X_corpus_test.npy\",   allow_pickle=True)\n",
        "\n",
        "y_train = np.load(\"/content/drive/MyDrive/OpenClassroom/y_train.npy\"     , allow_pickle=True)\n",
        "y_test = np.load(\"/content/drive/MyDrive/OpenClassroom/y_test.npy\",   allow_pickle=True)\n",
        "\n",
        "label_list = np.load(\"/content/drive/MyDrive/OpenClassroom/label_list.npy\"     , allow_pickle=True)\n",
        "\n",
        "X_train = [ np.append(X_title_train[i], X_corpus_train[i]) for i in range (len( X_title_train)) ]\n",
        "X_test = [ np.append(X_title_test[i], X_corpus_test[i]) for i in range (len( X_title_test)) ]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_train_b = mlb.fit_transform(y_train)\n",
        "y_test_b = mlb.transform(y_test)"
      ],
      "metadata": {
        "id": "J-xWVEn28vC7"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks\n",
        "\n",
        "Multilayers perceptron (MLP) for multi-label classification\n",
        "\n",
        "loss funstion : binary cross-entropy loss function\n",
        "\n",
        "activation function : ReLU in the hidden layers\n",
        "\n",
        "adam version of stochastic gradient descent"
      ],
      "metadata": {
        "id": "uS-D3tkeHOPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding preprocessing"
      ],
      "metadata": {
        "id": "BJxW23-VJqpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list = [ x.tolist() for x in X_train]"
      ],
      "metadata": {
        "id": "if85zWvcMoHq"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Création et entraînement du modèle Word2Vec\n",
        "w2v_size=300\n",
        "w2v_window=5\n",
        "w2v_min_count=1\n",
        "w2v_epochs=100\n",
        "maxlen = 24 # adapt to length of sentences\n",
        "\n",
        "sentences = X_train_list\n",
        "\n",
        "print(\"Build & train Word2Vec model ...\")\n",
        "w2v_model = Word2Vec(min_count=w2v_min_count, window=w2v_window,\n",
        "                                                vector_size=w2v_size,\n",
        "                                                seed=42,\n",
        "                                                workers=1)"
      ],
      "metadata": {
        "id": "GF6stGYZMmbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7064a51-5c35-4df6-9ef1-f9a17d6e3743"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build & train Word2Vec model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason for separating the trained vectors into KeyedVectors is that if you don’t need the full model state any more (don’t need to continue training), the state can discarded, resulting in a much smaller and faster object that can be mmapped for lightning fast loading and sharing the vectors in RAM between processes:\n",
        "\n",
        "Gensim can also load word vectors in the “word2vec C format”, as a KeyedVectors instance:"
      ],
      "metadata": {
        "id": "Hc3ujOIt5sWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try :\n",
        "  model_vectors = KeyedVectors.load(\"/content/drive/MyDrive/OpenClassroom/model_vectors.wv\", mmap='r')\n",
        "except :\n",
        "  w2v_model.build_vocab(sentences)\n",
        "  w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=w2v_epochs)\n",
        "  model_vectors = w2v_model.wv\n",
        "  w2v_words = model_vectors.index_to_key\n",
        "  print(\"Vocabulary size: %i\" % len(w2v_words))\n",
        "  print(\"Word2Vec trained\")\n",
        "\n",
        "  model_vectors.save(\"/content/drive/MyDrive/OpenClassroom/model_vectors.wv\")"
      ],
      "metadata": {
        "id": "KYe3tvkgMGS7"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w2v_model)"
      ],
      "metadata": {
        "id": "DMBiPMxDQsjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "865db21a-6ed0-4fb3-81d2-f8f1652abc97"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=0, vector_size=300, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2word = corpora.Dictionary(X_train)\n",
        "d = dict(zip(label_list, range(0,len(label_list))))"
      ],
      "metadata": {
        "id": "t-xufgfQallL"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2word = corpora.Dictionary(X_train)\n",
        "x_train_ids = [ id2word.doc2idx(tokens) for tokens in X_train]\n",
        "x_test_ids = [ id2word.doc2idx(tokens) for tokens in X_test]"
      ],
      "metadata": {
        "id": "jaLWWIQLOJBS"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = np.max([ len(x) for x in x_train_ids])\n",
        "print(f\"max_length : {max_length}\")"
      ],
      "metadata": {
        "id": "-NCXNAT_RrMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c994365-07fe-4629-cfd5-91ad74ebc196"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_length : 2282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding matrix"
      ],
      "metadata": {
        "id": "ETr4guPjpjau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(model_vectors[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZM-9CW-qch7",
        "outputId": "9235cfae-1754-4aec-eeac-0380f83d3416"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_vocab_size = len(model_vectors.key_to_index)\n",
        "w2vec_dim = len(model_vectors[0])\n",
        "word2vec_embedding_matrix = np.zeros((word2vec_vocab_size, w2vec_dim))\n",
        "\n",
        "for word in model_vectors.key_to_index :\n",
        "\n",
        "  embedding_vector = model_vectors[word]\n",
        "  if embedding_vector is not None :\n",
        "    idx =  model_vectors.key_to_index[word]\n",
        "    word2vec_embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "print(\"Embedding matrix: %s\" % str(word2vec_embedding_matrix.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "087wFGULpmS9",
        "outputId": "5656f95f-8d51-456d-e982-8ab9e702e207"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix: (41340, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply padding"
      ],
      "metadata": {
        "id": "nfo8-bOfbMLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_pad = pad_sequences(x_train_ids, maxlen=max_length, padding='pre')\n",
        "x_test_pad = pad_sequences(x_test_ids, maxlen=max_length, padding='pre')"
      ],
      "metadata": {
        "id": "r91-eP4gY51k"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_pad[0]"
      ],
      "metadata": {
        "id": "GiEdzORBbH1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fef236f-10a5-4a0c-8e82-99429e41ebb5"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0, ..., 71, 74, 79], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# model.add(Input(shape=(1,max_length),dtype='float64'))\n",
        "model.add(Embedding( word2vec_vocab_size, w2vec_dim,weights=[word2vec_embedding_matrix],  input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(30,activation='sigmoid'))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "fbkX2vkYQWml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3937b14a-5ee8-48ad-959f-f435e1b6d576"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 2282, 300)         12402000  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 684600)            0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 30)                20538030  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,940,030\n",
            "Trainable params: 32,940,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GEpi_Spe3KSF"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "W9iBb2fu8k6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d74248-a2d4-47ed-a164-83e4a62d54c3"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([8]), list([27]), list([2, 7, 14]), ..., list([3, 9]),\n",
              "       list([17]), list([0])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train_pad, y_train_b, epochs=5)"
      ],
      "metadata": {
        "id": "qp97pRuR8bu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9942339f-43c2-41ba-92d0-b863a750ae20"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "50/50 [==============================] - 32s 623ms/step - loss: 44.9162 - accuracy: 0.0737\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 28s 567ms/step - loss: 22.2463 - accuracy: 0.0850\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 28s 551ms/step - loss: 23.3010 - accuracy: 0.0800\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 26s 524ms/step - loss: 21.8060 - accuracy: 0.1013\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 27s 546ms/step - loss: 21.3158 - accuracy: 0.1219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb0e5b3b730>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test_pad)"
      ],
      "metadata": {
        "id": "O8ofX6_a__Ne",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1bc97b10-fccb-414e-bea5-dec4ea5a2e04"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-b3c6f882ddcd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_6/embedding_6/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-120-b3c6f882ddcd>\", line 1, in <cell line: 1>\n      y_pred = model.predict(x_test_pad)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/core/embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_6/embedding_6/embedding_lookup'\nindices[13,2196] = -1 is not in [0, 41340)\n\t [[{{node sequential_6/embedding_6/embedding_lookup}}]] [Op:__inference_predict_function_7661]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_nn = (y_pred > 0.1).astype(np.float32)"
      ],
      "metadata": {
        "id": "bEzGLzqP_3xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "precision_em      = average_precision_score(y_test_b, y_pred, average='micro')\n",
        "jaccard_score_em = jaccard_score(y_test_b, y_pred, average='micro')"
      ],
      "metadata": {
        "id": "ezkkFTFV9e8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vocab is the number of unique words in my train data.\n",
        "The size is the dimension in output of my embedding."
      ],
      "metadata": {
        "id": "jl4XyvqgK4h0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OzX5AL7uKDfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "XEq4gPPrJ83U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "model.wv.similarity('splint','tableview')"
      ],
      "metadata": {
        "id": "mdTQlZa_KD_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_embedding = model.wv[X_train]\n",
        "X_test_embedding = model.wv[X_test]"
      ],
      "metadata": {
        "id": "aAG5dW41KGSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding preprocessing"
      ],
      "metadata": {
        "id": "fVB4Ecs7Jp5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_model = Sequential()\n",
        "word_model.add(Embedding(vocab_size, embed_size,\n",
        "                         embeddings_initializer=\"glorot_uniform\",\n",
        "                         input_length=1))\n",
        "word_model.add(Reshape((embed_size, )))\n",
        "\n",
        "context_model = Sequential()\n",
        "context_model.add(Embedding(vocab_size, embed_size,\n",
        "                  embeddings_initializer=\"glorot_uniform\",\n",
        "                  input_length=1))\n",
        "context_model.add(Reshape((embed_size,)))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Merge([word_model, context_model], mode=\"dot\"))\n",
        "model.add(Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")"
      ],
      "metadata": {
        "id": "wjBTvm_QHUJM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}